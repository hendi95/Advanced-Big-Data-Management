{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ddd06f7-3837-4ef9-8d70-cfe075736595",
   "metadata": {},
   "source": [
    "# IST769 Final Exam\n",
    "\n",
    "**INSTRUCTIONS FOR HIGHEST GRADE POSSIBLE**\n",
    "\n",
    "Unless you are explicitly instructed otherwise, answer each of the following using PySpark / Spark SQL. For any queries you write make sure to include a `printSchema()` and sample(s) of the output which clearly demonstrates the code is correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25feebd0-d09b-4233-b9af-ec965875930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo cp /home/jovyan/work/jars/neo4j-connector-apache-spark_2.12-4.1.0_for_spark_3.jar /usr/local/spark/jars/neo4j-connector-apache-spark_2.12-4.1.0_for_spark_3.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4308c98a-a418-4120-9ee7-05992d21e0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q cassandra-driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c73c8d6-8ab6-44a8-8a78-51598b8c07be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12353bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR NAME ========>   Hendi Kushta\n",
    "# YOUR SU EMAIL ====>  hkushta@syr.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91718b91-ceae-416d-b96c-053a5d844676",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "In the cell below configure a spark session that is configured to connect to `mongodb`, `minio`, `cassandra`, '`elasticsearch` and `neo4j`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef5ecf9f-0798-4bc9-8896-229a0faade48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/jovyan/.ivy2/cache\n",
      "The jars for the packages stored in: /home/jovyan/.ivy2/jars\n",
      "org.mongodb.spark#mongo-spark-connector_2.12 added as a dependency\n",
      "com.datastax.spark#spark-cassandra-connector-assembly_2.12 added as a dependency\n",
      "com.datastax.spark#spark-cassandra-connector_2.12 added as a dependency\n",
      "org.elasticsearch#elasticsearch-spark-20_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-85d82a9b-23c7-428c-859a-64a2d9dc1923;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.mongodb.spark#mongo-spark-connector_2.12;3.0.1 in central\n",
      "\tfound org.mongodb#mongodb-driver-sync;4.0.5 in central\n",
      "\tfound org.mongodb#bson;4.0.5 in central\n",
      "\tfound org.mongodb#mongodb-driver-core;4.0.5 in central\n",
      "\tfound com.datastax.spark#spark-cassandra-connector-assembly_2.12;3.1.0 in central\n",
      "\tfound com.datastax.spark#spark-cassandra-connector_2.12;3.1.0 in central\n",
      "\tfound com.datastax.spark#spark-cassandra-connector-driver_2.12;3.1.0 in central\n",
      "\tfound com.datastax.oss#java-driver-core-shaded;4.12.0 in central\n",
      "\tfound com.datastax.oss#native-protocol;1.5.0 in central\n",
      "\tfound com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 in central\n",
      "\tfound com.typesafe#config;1.4.1 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.26 in central\n",
      "\tfound io.dropwizard.metrics#metrics-core;4.1.18 in central\n",
      "\tfound org.hdrhistogram#HdrHistogram;2.1.12 in central\n",
      "\tfound org.reactivestreams#reactive-streams;1.0.3 in central\n",
      "\tfound com.github.stephenc.jcip#jcip-annotations;1.0-1 in central\n",
      "\tfound com.github.spotbugs#spotbugs-annotations;3.1.12 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound com.datastax.oss#java-driver-mapper-runtime;4.12.0 in central\n",
      "\tfound com.datastax.oss#java-driver-query-builder;4.12.0 in central\n",
      "\tfound org.apache.commons#commons-lang3;3.10 in central\n",
      "\tfound com.thoughtworks.paranamer#paranamer;2.8 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.12.11 in central\n",
      "\tfound org.elasticsearch#elasticsearch-spark-20_2.12;7.15.0 in central\n",
      "\tfound commons-logging#commons-logging;1.1.1 in central\n",
      "\tfound javax.xml.bind#jaxb-api;2.3.1 in central\n",
      "\tfound com.google.protobuf#protobuf-java;2.5.0 in central\n",
      "\tfound org.apache.spark#spark-yarn_2.12;2.4.4 in central\n",
      ":: resolution report :: resolve 1259ms :: artifacts dl 28ms\n",
      "\t:: modules in use:\n",
      "\tcom.datastax.oss#java-driver-core-shaded;4.12.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-mapper-runtime;4.12.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-query-builder;4.12.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 from central in [default]\n",
      "\tcom.datastax.oss#native-protocol;1.5.0 from central in [default]\n",
      "\tcom.datastax.spark#spark-cassandra-connector-assembly_2.12;3.1.0 from central in [default]\n",
      "\tcom.datastax.spark#spark-cassandra-connector-driver_2.12;3.1.0 from central in [default]\n",
      "\tcom.datastax.spark#spark-cassandra-connector_2.12;3.1.0 from central in [default]\n",
      "\tcom.github.spotbugs#spotbugs-annotations;3.1.12 from central in [default]\n",
      "\tcom.github.stephenc.jcip#jcip-annotations;1.0-1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;2.5.0 from central in [default]\n",
      "\tcom.thoughtworks.paranamer#paranamer;2.8 from central in [default]\n",
      "\tcom.typesafe#config;1.4.1 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.1 from central in [default]\n",
      "\tio.dropwizard.metrics#metrics-core;4.1.18 from central in [default]\n",
      "\tjavax.xml.bind#jaxb-api;2.3.1 from central in [default]\n",
      "\torg.apache.commons#commons-lang3;3.10 from central in [default]\n",
      "\torg.apache.spark#spark-yarn_2.12;2.4.4 from central in [default]\n",
      "\torg.elasticsearch#elasticsearch-spark-20_2.12;7.15.0 from central in [default]\n",
      "\torg.hdrhistogram#HdrHistogram;2.1.12 from central in [default]\n",
      "\torg.mongodb#bson;4.0.5 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-core;4.0.5 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-sync;4.0.5 from central in [default]\n",
      "\torg.mongodb.spark#mongo-spark-connector_2.12;3.0.1 from central in [default]\n",
      "\torg.reactivestreams#reactive-streams;1.0.3 from central in [default]\n",
      "\torg.scala-lang#scala-reflect;2.12.11 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.26 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\torg.scala-lang#scala-reflect;2.12.8 by [org.scala-lang#scala-reflect;2.12.11] in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.6 by [org.slf4j#slf4j-api;1.7.26] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   30  |   0   |   0   |   2   ||   24  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-85d82a9b-23c7-428c-859a-64a2d9dc1923\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 24 already retrieved (0kB/16ms)\n",
      "24/04/26 23:06:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "#1 Spark session\n",
    "\n",
    "# MongoDB Configuration\n",
    "mongo_user = \"admin\"\n",
    "mongo_passwd = \"mongopw\"\n",
    "mongo_uri = f\"mongodb://{mongo_user}:{mongo_passwd}@mongo:27017/admin?authSource=admin\"\n",
    "\n",
    "# Minio Configuration\n",
    "s3_host = \"minio\"\n",
    "s3_url = f\"http://{s3_host}:9000\"\n",
    "s3_key = \"minio\"\n",
    "s3_secret = \"SU2orange!\"\n",
    "s3_bucket = \"enrollments\"\n",
    "\n",
    "# Cassandra Configuration\n",
    "cassandra_host = \"cassandra\"\n",
    "\n",
    "# Elasticsearch Configuration\n",
    "elastic_host = \"elasticsearch\"\n",
    "elastic_port = \"9200\"\n",
    "\n",
    "# Neo4j Configuration\n",
    "bolt_url = \"bolt://neo4j:7687\"\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName('jupyter-pyspark') \\\n",
    "    .config(\"spark.mongodb.input.uri\", mongo_uri) \\\n",
    "    .config(\"spark.mongodb.output.uri\", mongo_uri) \\\n",
    "    .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1,com.datastax.spark:spark-cassandra-connector-assembly_2.12:3.1.0,com.datastax.spark:spark-cassandra-connector_2.12:3.1.0,org.elasticsearch:elasticsearch-spark-20_2.12:7.15.0\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", s3_url) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", s3_key) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", s3_secret) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.fast.upload\", True) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", True) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .config(\"spark.cassandra.connection.host\", cassandra_host) \\\n",
    "    .config(\"spark.es.nodes\", elastic_host) \\\n",
    "    .config(\"spark.es.port\", elastic_port) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee055a5-7a8f-4739-a3f5-a52d981ea05e",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Demonstrate you can read the process-oriented data `enrollments` and `sections` from `minio` using PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d50367be-c7ac-43b0-b820-54e4b7d83c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------+------+-------+-----------------+-----+------------+\n",
      "|term|course_enrollment|course|section|       student_id|grade|grade_points|\n",
      "+----+-----------------+------+-------+-----------------+-----+------------+\n",
      "|1221|                1|IST659|   M001|      orenjouglad|    C|         2.0|\n",
      "|1221|                2|IST659|   M001|      billmelator|    A|         4.0|\n",
      "|1221|                3|IST659|   M001|       morrisless|    A|         4.0|\n",
      "|1221|                4|IST659|   M001|amberwavesofgrain|   A-|       3.667|\n",
      "|1221|                5|IST659|   M001|         abbykuss|    A|         4.0|\n",
      "+----+-----------------+------+-------+-----------------+-----+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- term: integer (nullable = true)\n",
      " |-- course_enrollment: integer (nullable = true)\n",
      " |-- course: string (nullable = true)\n",
      " |-- section: string (nullable = true)\n",
      " |-- student_id: string (nullable = true)\n",
      " |-- grade: string (nullable = true)\n",
      " |-- grade_points: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2a enrollments\n",
    "\n",
    "# read from minio\n",
    "df_enrollments = spark.read.csv(\"s3a://enrollments/enrollments.csv\",header=True, inferSchema=True)\n",
    "df_enrollments.show(5)\n",
    "df_enrollments.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b415479-5acf-42dc-b535-c80bc62d239b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+-------+----------+--------+\n",
      "|term|course|section|enrollment|capacity|\n",
      "+----+------+-------+----------+--------+\n",
      "|1221|IST659|   M001|        20|      20|\n",
      "|1221|IST659|   M002|        20|      20|\n",
      "|1221|IST722|   M001|        25|      28|\n",
      "|1221|IST615|   M001|        22|      28|\n",
      "|1221|IST621|   M001|        22|      24|\n",
      "+----+------+-------+----------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- term: integer (nullable = true)\n",
      " |-- course: string (nullable = true)\n",
      " |-- section: string (nullable = true)\n",
      " |-- enrollment: integer (nullable = true)\n",
      " |-- capacity: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2b sections \n",
    "\n",
    "# read from minio\n",
    "df_sections = spark.read.csv(\"s3a://enrollments/sections.csv\",header=True, inferSchema=True)\n",
    "df_sections.show(5)\n",
    "df_sections.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74906498-d775-451f-befd-5e88595b7009",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Demonstrate you can read the reference-oriented data `terms`, `students`, `courses`, and `program` reference data from `MongoDb` using PySpark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f928bc1-1306-42d7-a073-c7673dde4f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+----+-----------+--------+----+\n",
      "| _id|academic_year|code|       name|semester|year|\n",
      "+----+-------------+----+-----------+--------+----+\n",
      "|1221|    2021-2022|1221|  Fall 2021|    Fall|2021|\n",
      "|1222|    2021-2022|1222|Spring 2022|  Spring|2022|\n",
      "|1231|    2022-2023|1231|  Fall 2022|    Fall|2022|\n",
      "|1232|    2022-2023|1232|Spring 2023|  Spring|2023|\n",
      "+----+-------------+----+-----------+--------+----+\n",
      "\n",
      "root\n",
      " |-- _id: string (nullable = true)\n",
      " |-- academic_year: string (nullable = true)\n",
      " |-- code: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- semester: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3a terms \n",
    "\n",
    "# read from Mongo\n",
    "df_terms = spark.read.format(\"mongo\") \\\n",
    "    .option(\"database\",\"ischooldb\") \\\n",
    "    .option(\"collection\",\"terms\") \\\n",
    "    .load()\n",
    "\n",
    "df_terms.show(5)\n",
    "df_terms.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b917eaca-2e3e-45ab-84aa-bc2f07bf6e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+-------+--------------------+--------------------+----------------+--------------------+-------------+--------------------+\n",
      "|   _id|  code|credits|         description|elective_in_programs| key_assignments|                name|prerequisites|required_in_programs|\n",
      "+------+------+-------+--------------------+--------------------+----------------+--------------------+-------------+--------------------+\n",
      "|IST659|IST659|      3|Definition, devel...|                  []|       [project]|Data Administrati...|           []|            [IS, DS]|\n",
      "|IST722|IST722|      3|Introduction to c...|                [IS]| [project, exam]|    Data Warehousing|     [IST659]|                  []|\n",
      "|IST769|IST769|      3|Analyze relationa...|                [DS]| [project, exam]|Advanced Big Data...|     [IST659]|                  []|\n",
      "|IST615|IST615|      3|Cloud services cr...|                  []|[project, paper]|    Cloud Management|           []|            [IS, DS]|\n",
      "|IST714|IST714|      3|Advanced, lab-bas...|            [IS, DS]|       [project]|  Cloud Architecture|     [IST615]|                  []|\n",
      "+------+------+-------+--------------------+--------------------+----------------+--------------------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- _id: string (nullable = true)\n",
      " |-- code: string (nullable = true)\n",
      " |-- credits: integer (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- elective_in_programs: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- key_assignments: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- prerequisites: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- required_in_programs: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3b courses\n",
    "\n",
    "# read from Mongo\n",
    "df_courses = spark.read.format(\"mongo\") \\\n",
    "    .option(\"database\",\"ischooldb\") \\\n",
    "    .option(\"collection\",\"courses\") \\\n",
    "    .load()\n",
    "\n",
    "df_courses.show(5)\n",
    "df_courses.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f483a03-3da6-4efa-95d7-06c82e556400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-------+--------------------+--------------------+--------------------+-----------+\n",
      "|_id|code|credits|    elective_courses|                name|    required_courses|       type|\n",
      "+---+----+-------+--------------------+--------------------+--------------------+-----------+\n",
      "| IS|  IS|     36|[IST722, IST714, ...| Information Systems|[IST659, IST615, ...|    Masters|\n",
      "| DS|  DS|     34|    [IST769, IST714]|        Data Science|[IST659, IST615, ...|    Masters|\n",
      "|BDC| BDC|      9|                null|Data Engineering ...|[IST659, IST722, ...|Certificate|\n",
      "|CCC| CCC|      9|                null|Cloud Computing C...|[IST621, IST615, ...|Certificate|\n",
      "|MLC| MLC|      9|                null|Machine Learning ...|[IST687, IST707, ...|Certificate|\n",
      "+---+----+-------+--------------------+--------------------+--------------------+-----------+\n",
      "\n",
      "root\n",
      " |-- _id: string (nullable = true)\n",
      " |-- code: string (nullable = true)\n",
      " |-- credits: integer (nullable = true)\n",
      " |-- elective_courses: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- required_courses: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3c Programs\n",
    "\n",
    "# read from Mongo\n",
    "df_programs = spark.read.format(\"mongo\") \\\n",
    "    .option(\"database\",\"ischooldb\") \\\n",
    "    .option(\"collection\",\"programs\") \\\n",
    "    .load()\n",
    "\n",
    "df_programs.show(5)\n",
    "df_programs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88d87294-61eb-4dd4-8b7a-5c280b6b7c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+-------+\n",
      "|         _id|         name|program|\n",
      "+------------+-------------+-------+\n",
      "|    abbykuss|    Abby Kuss|     DS|\n",
      "|  adamantium|  Adam Antium|     IS|\n",
      "|   addieowse|   Addie Owse|     IS|\n",
      "|aidensomewun|Aiden Somewun|     IS|\n",
      "|aidenknowone|Aiden Knowone|     DS|\n",
      "+------------+-------------+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- _id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- program: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3d students\n",
    "\n",
    "# read from Mongo\n",
    "df_students = spark.read.format(\"mongo\") \\\n",
    "    .option(\"database\",\"ischooldb\") \\\n",
    "    .option(\"collection\",\"students\") \\\n",
    "    .load()\n",
    "\n",
    "df_students.show(5)\n",
    "df_students.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abfca28-8272-46ee-b98c-6a263be01c56",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Prepare the `section` data for loading into `cassandra` and `elasticsearch` with Spark or Spark SQL. Just PREPARE it do not LOAD it. Remember that we want this data to be as wide as possible, so include all relevant reference data. For example, the `section` data should include `term` attributes like `year`,  `academic year`, etc... and from `course`, attributes like `credits`, `name`, `prerequisites`, etc... \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e8a9218-9dc1-4e69-87d8-90274d579ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 33:===============================================>       (87 + 1) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+-------+----------+--------+-----------+-------------+---------+-------------+--------------+----------------+--------------------+----------------+--------------------+-------------+--------------------+\n",
      "|term|course|section|enrollment|capacity|  term_name|term_semester|term_year|academic_year|course_credits|     course_name|  course_description| key_assignments|elective_in_programs|prerequisites|required_in_programs|\n",
      "+----+------+-------+----------+--------+-----------+-------------+---------+-------------+--------------+----------------+--------------------+----------------+--------------------+-------------+--------------------+\n",
      "|1232|IST615|   M001|        21|      28|Spring 2023|       Spring|     2023|    2022-2023|             3|Cloud Management|Cloud services cr...|[project, paper]|                  []|           []|            [IS, DS]|\n",
      "|1232|IST615|   M002|        20|      24|Spring 2023|       Spring|     2023|    2022-2023|             3|Cloud Management|Cloud services cr...|[project, paper]|                  []|           []|            [IS, DS]|\n",
      "|1222|IST615|   M001|        19|      24|Spring 2022|       Spring|     2022|    2021-2022|             3|Cloud Management|Cloud services cr...|[project, paper]|                  []|           []|            [IS, DS]|\n",
      "|1231|IST615|   M001|        21|      24|  Fall 2022|         Fall|     2022|    2022-2023|             3|Cloud Management|Cloud services cr...|[project, paper]|                  []|           []|            [IS, DS]|\n",
      "|1221|IST615|   M001|        22|      28|  Fall 2021|         Fall|     2021|    2021-2022|             3|Cloud Management|Cloud services cr...|[project, paper]|                  []|           []|            [IS, DS]|\n",
      "+----+------+-------+----------+--------+-----------+-------------+---------+-------------+--------------+----------------+--------------------+----------------+--------------------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- term: integer (nullable = true)\n",
      " |-- course: string (nullable = true)\n",
      " |-- section: string (nullable = true)\n",
      " |-- enrollment: integer (nullable = true)\n",
      " |-- capacity: integer (nullable = true)\n",
      " |-- term_name: string (nullable = true)\n",
      " |-- term_semester: string (nullable = true)\n",
      " |-- term_year: integer (nullable = true)\n",
      " |-- academic_year: string (nullable = true)\n",
      " |-- course_credits: integer (nullable = true)\n",
      " |-- course_name: string (nullable = true)\n",
      " |-- course_description: string (nullable = true)\n",
      " |-- key_assignments: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- elective_in_programs: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- prerequisites: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- required_in_programs: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#4 wide_sections\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Joining section data with terms, courses, and programs\n",
    "df_sections_prep = df_sections.alias(\"sections\").join(df_terms.alias(\"terms\"), col(\"sections.term\") == col(\"terms._id\"), how=\"left\") \\\n",
    "    .join(df_courses.alias(\"courses\"), col(\"sections.course\") == col(\"courses._id\"), how=\"left\") \\\n",
    "    .select(\n",
    "        col(\"sections.term\"),\n",
    "        col(\"sections.course\"),\n",
    "        col(\"sections.section\"),\n",
    "        col(\"sections.enrollment\"),\n",
    "        col(\"sections.capacity\"),\n",
    "        col(\"terms.name\").alias(\"term_name\"),\n",
    "        col(\"terms.semester\").alias(\"term_semester\"),\n",
    "        col(\"terms.year\").alias(\"term_year\"),\n",
    "        col(\"terms.academic_year\"),\n",
    "        col(\"courses.credits\").alias(\"course_credits\"),\n",
    "        col(\"courses.name\").alias(\"course_name\"),\n",
    "        col(\"courses.description\").alias(\"course_description\"),\n",
    "        col(\"courses.key_assignments\"),\n",
    "        col(\"courses.elective_in_programs\"),\n",
    "        col(\"courses.prerequisites\"),\n",
    "        col(\"courses.required_in_programs\")\n",
    "    )\n",
    "\n",
    "df_sections_prep.show(5)\n",
    "df_sections_prep.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f972cf-8ab1-48fe-b2ff-607acc11e05d",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "Use the `cassandra-driver` example from class to write python code to connect to cassandra from within Jupyter and create a keyspace named `ischooldb`. Design a cassandra table called `sections` to store the data from question 4. Appropriate key design is important! Please explain your justification for key below your table definition. Provide clear evidence that your table was created by querying the empty table in spark and use `printSchema()` to show the schema. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4015e68d-c1d0-4bb6-962e-f42bdaeb28c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 create cassandra table for wide_sections\n",
    "\n",
    "from cassandra.cluster import Cluster\n",
    "\n",
    "# Connect to Cassandra\n",
    "with Cluster([cassandra_host]) as cluster:\n",
    "    session = cluster.connect()\n",
    "    \n",
    "    # Create keyspace\n",
    "    session.execute(\"CREATE KEYSPACE IF NOT EXISTS ischooldb WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1};\")\n",
    "    \n",
    "    # Switch to ischooldb keyspace\n",
    "    session.set_keyspace('ischooldb')\n",
    "    \n",
    "    # Create table wide_sections\n",
    "    sql = '''\n",
    "    CREATE TABLE IF NOT EXISTS wide_sections (\n",
    "        term INT,\n",
    "        course TEXT,\n",
    "        section TEXT,\n",
    "        enrollment INT,\n",
    "        capacity INT,\n",
    "        term_name TEXT,\n",
    "        term_semester TEXT,\n",
    "        term_year INT,\n",
    "        academic_year TEXT,\n",
    "        course_credits INT,\n",
    "        course_name TEXT,\n",
    "        course_description TEXT,\n",
    "        key_assignments TEXT,\n",
    "        elective_in_programs TEXT,\n",
    "        prerequisites TEXT,\n",
    "        required_in_programs TEXT,\n",
    "        PRIMARY KEY ((term_semester, term_year), term, course, section)\n",
    "    );\n",
    "    '''\n",
    "    \n",
    "    session.execute(sql)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a06feb69-1eab-400e-8f6f-4de25b9bebb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 35:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+----+------+-------+-------------+--------+--------------+------------------+-----------+--------------------+----------+---------------+-------------+--------------------+---------+\n",
      "|term_semester|term_year|term|course|section|academic_year|capacity|course_credits|course_description|course_name|elective_in_programs|enrollment|key_assignments|prerequisites|required_in_programs|term_name|\n",
      "+-------------+---------+----+------+-------+-------------+--------+--------------+------------------+-----------+--------------------+----------+---------------+-------------+--------------------+---------+\n",
      "+-------------+---------+----+------+-------+-------------+--------+--------------+------------------+-----------+--------------------+----------+---------------+-------------+--------------------+---------+\n",
      "\n",
      "root\n",
      " |-- term_semester: string (nullable = false)\n",
      " |-- term_year: integer (nullable = false)\n",
      " |-- term: integer (nullable = true)\n",
      " |-- course: string (nullable = true)\n",
      " |-- section: string (nullable = true)\n",
      " |-- academic_year: string (nullable = true)\n",
      " |-- capacity: integer (nullable = true)\n",
      " |-- course_credits: integer (nullable = true)\n",
      " |-- course_description: string (nullable = true)\n",
      " |-- course_name: string (nullable = true)\n",
      " |-- elective_in_programs: string (nullable = true)\n",
      " |-- enrollment: integer (nullable = true)\n",
      " |-- key_assignments: string (nullable = true)\n",
      " |-- prerequisites: string (nullable = true)\n",
      " |-- required_in_programs: string (nullable = true)\n",
      " |-- term_name: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Query the Cassandra table (wide_sections) using the DataFrame (df_sections_prep)\n",
    "cassandra_df = spark.read\\\n",
    "    .format(\"org.apache.spark.sql.cassandra\")\\\n",
    "    .options(table=\"wide_sections\", keyspace=\"ischooldb\")\\\n",
    "    .load()\n",
    "\n",
    "cassandra_df.show()\n",
    "\n",
    "# Display the schema of the Cassandra DataFrame\n",
    "cassandra_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee71b3b5-03d7-456d-a64f-f3c5f0c93836",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Load the data frame you created in question 4 into the `cassandra` table you created in question 5. Demonstrate the data is in the table by querying back it with PySpark. Make sure you can run the code multiple times and each time it replaces the existing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59e9aac0-da49-4c82-8e3f-184b5f1d9eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#6 load wide_sections into cassandra\n",
    "\n",
    "df_sections_prep.write \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .mode(\"Overwrite\") \\\n",
    "    .option(\"table\", \"wide_sections\") \\\n",
    "    .option(\"keyspace\", \"ischooldb\") \\\n",
    "    .option(\"confirm.truncate\", \"true\") \\\n",
    "    .option(\"spark.cassandra.connection.host\", cassandra_host) \\\n",
    "    .save()\n",
    "\n",
    "# have to truncate and then overwrite in cassandra in order to run the code multiple times and each time to replace the existing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42e0277d-7c82-469e-9c61-2e66787dbc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_semester</th>\n",
       "      <th>term_year</th>\n",
       "      <th>term</th>\n",
       "      <th>course</th>\n",
       "      <th>section</th>\n",
       "      <th>academic_year</th>\n",
       "      <th>capacity</th>\n",
       "      <th>course_credits</th>\n",
       "      <th>course_description</th>\n",
       "      <th>course_name</th>\n",
       "      <th>elective_in_programs</th>\n",
       "      <th>enrollment</th>\n",
       "      <th>key_assignments</th>\n",
       "      <th>prerequisites</th>\n",
       "      <th>required_in_programs</th>\n",
       "      <th>term_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spring</td>\n",
       "      <td>2022</td>\n",
       "      <td>1222</td>\n",
       "      <td>IST615</td>\n",
       "      <td>M001</td>\n",
       "      <td>2021-2022</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>Cloud services creation and management. Practi...</td>\n",
       "      <td>Cloud Management</td>\n",
       "      <td>[]</td>\n",
       "      <td>19</td>\n",
       "      <td>[project,paper]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[IS,DS]</td>\n",
       "      <td>Spring 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spring</td>\n",
       "      <td>2022</td>\n",
       "      <td>1222</td>\n",
       "      <td>IST621</td>\n",
       "      <td>M001</td>\n",
       "      <td>2021-2022</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>Information and technology management overview...</td>\n",
       "      <td>Information Management and Technology</td>\n",
       "      <td>[]</td>\n",
       "      <td>28</td>\n",
       "      <td>[paper]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[IS]</td>\n",
       "      <td>Spring 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spring</td>\n",
       "      <td>2022</td>\n",
       "      <td>1222</td>\n",
       "      <td>IST621</td>\n",
       "      <td>M002</td>\n",
       "      <td>2021-2022</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>Information and technology management overview...</td>\n",
       "      <td>Information Management and Technology</td>\n",
       "      <td>[]</td>\n",
       "      <td>22</td>\n",
       "      <td>[paper]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[IS]</td>\n",
       "      <td>Spring 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spring</td>\n",
       "      <td>2022</td>\n",
       "      <td>1222</td>\n",
       "      <td>IST659</td>\n",
       "      <td>M001</td>\n",
       "      <td>2021-2022</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>Definition, development, and management of dat...</td>\n",
       "      <td>Data Administration Concepts and Database Mana...</td>\n",
       "      <td>[]</td>\n",
       "      <td>24</td>\n",
       "      <td>[project]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[IS,DS]</td>\n",
       "      <td>Spring 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spring</td>\n",
       "      <td>2022</td>\n",
       "      <td>1222</td>\n",
       "      <td>IST687</td>\n",
       "      <td>M001</td>\n",
       "      <td>2021-2022</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>Introduces information professionals to fundam...</td>\n",
       "      <td>Introduction to Data Science</td>\n",
       "      <td>[IS]</td>\n",
       "      <td>18</td>\n",
       "      <td>[project,exam]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[DS]</td>\n",
       "      <td>Spring 2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  term_semester  term_year  term  course section academic_year  capacity  \\\n",
       "0        Spring       2022  1222  IST615    M001     2021-2022        24   \n",
       "1        Spring       2022  1222  IST621    M001     2021-2022        28   \n",
       "2        Spring       2022  1222  IST621    M002     2021-2022        24   \n",
       "3        Spring       2022  1222  IST659    M001     2021-2022        24   \n",
       "4        Spring       2022  1222  IST687    M001     2021-2022        20   \n",
       "\n",
       "   course_credits                                 course_description  \\\n",
       "0               3  Cloud services creation and management. Practi...   \n",
       "1               3  Information and technology management overview...   \n",
       "2               3  Information and technology management overview...   \n",
       "3               3  Definition, development, and management of dat...   \n",
       "4               3  Introduces information professionals to fundam...   \n",
       "\n",
       "                                         course_name elective_in_programs  \\\n",
       "0                                   Cloud Management                   []   \n",
       "1              Information Management and Technology                   []   \n",
       "2              Information Management and Technology                   []   \n",
       "3  Data Administration Concepts and Database Mana...                   []   \n",
       "4                       Introduction to Data Science                 [IS]   \n",
       "\n",
       "   enrollment  key_assignments prerequisites required_in_programs    term_name  \n",
       "0          19  [project,paper]            []              [IS,DS]  Spring 2022  \n",
       "1          28          [paper]            []                 [IS]  Spring 2022  \n",
       "2          22          [paper]            []                 [IS]  Spring 2022  \n",
       "3          24        [project]            []              [IS,DS]  Spring 2022  \n",
       "4          18   [project,exam]            []                 [DS]  Spring 2022  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read back from Cassandra\n",
    "df_sections_prep =spark.read.format(\"org.apache.spark.sql.cassandra\")\\\n",
    "    .options(table=\"wide_sections\", keyspace=\"ischooldb\") \\\n",
    "    .load()\n",
    "df_sections_prep.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a052fbcc-b7cc-4fa7-ba5d-09b3066c8b96",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "Since we did not learn how to create a custom elasticsearch mapping, before you can load the data into `elasticsearch` you will need to flatten the nested data. For example, `course_is_elective_in_programs` should generate 2 columns `course_is_elective_for_IS` and `course_is_elective_for_DS`. You'll need to repeat this step for `course_is_required_in_programs`. Omit the `course_prerequisites` and `course_key_assignments` column. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3b73af8-3d23-4da0-aab4-4f63d9aee205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|elective_in_programs|\n",
      "+--------------------+\n",
      "|             [IS,DS]|\n",
      "|                  []|\n",
      "|                [IS]|\n",
      "|                [DS]|\n",
      "+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|required_in_programs|\n",
      "+--------------------+\n",
      "|             [IS,DS]|\n",
      "|                  []|\n",
      "|                [IS]|\n",
      "|                [DS]|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sections_prep.select(\"elective_in_programs\").distinct().show()\n",
    "df_sections_prep.select(\"required_in_programs\").distinct().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99f91002-2880-4f4c-8392-9b869ce42172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+----+------+-------+-------------+--------+--------------+--------------------+--------------------+----------+-----------+-------------------------+-------------------------+-------------------------+-------------------------+\n",
      "|term_semester|term_year|term|course|section|academic_year|capacity|course_credits|  course_description|         course_name|enrollment|  term_name|course_is_elective_for_IS|course_is_elective_for_DS|course_is_required_for_IS|course_is_required_for_DS|\n",
      "+-------------+---------+----+------+-------+-------------+--------+--------------+--------------------+--------------------+----------+-----------+-------------------------+-------------------------+-------------------------+-------------------------+\n",
      "|       Spring|     2023|1232|IST615|   M001|    2022-2023|      28|             3|Cloud services cr...|    Cloud Management|        21|Spring 2023|                        0|                        0|                        1|                        1|\n",
      "|       Spring|     2023|1232|IST615|   M002|    2022-2023|      24|             3|Cloud services cr...|    Cloud Management|        20|Spring 2023|                        0|                        0|                        1|                        1|\n",
      "|       Spring|     2023|1232|IST621|   M001|    2022-2023|      28|             3|Information and t...|Information Manag...|        28|Spring 2023|                        0|                        0|                        1|                        0|\n",
      "|       Spring|     2023|1232|IST621|   M002|    2022-2023|      24|             3|Information and t...|Information Manag...|        21|Spring 2023|                        0|                        0|                        1|                        0|\n",
      "|       Spring|     2023|1232|IST659|   M001|    2022-2023|      20|             3|Definition, devel...|Data Administrati...|        20|Spring 2023|                        0|                        0|                        1|                        1|\n",
      "+-------------+---------+----+------+-------+-------------+--------+--------------+--------------------+--------------------+----------+-----------+-------------------------+-------------------------+-------------------------+-------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- term_semester: string (nullable = false)\n",
      " |-- term_year: integer (nullable = false)\n",
      " |-- term: integer (nullable = true)\n",
      " |-- course: string (nullable = true)\n",
      " |-- section: string (nullable = true)\n",
      " |-- academic_year: string (nullable = true)\n",
      " |-- capacity: integer (nullable = true)\n",
      " |-- course_credits: integer (nullable = true)\n",
      " |-- course_description: string (nullable = true)\n",
      " |-- course_name: string (nullable = true)\n",
      " |-- enrollment: integer (nullable = true)\n",
      " |-- term_name: string (nullable = true)\n",
      " |-- course_is_elective_for_IS: integer (nullable = false)\n",
      " |-- course_is_elective_for_DS: integer (nullable = false)\n",
      " |-- course_is_required_for_IS: integer (nullable = false)\n",
      " |-- course_is_required_for_DS: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#7 flatten `course_is_elective_in_programs` and `course_is_required_in_programs` \n",
    "\n",
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "# Flatten the elective_in_programs and course_is_required_in_programs columns\n",
    "df_sections_prep_flattened = df_sections_prep.withColumn(\"course_is_elective_for_IS\", when(col(\"elective_in_programs\").contains(\"IS\"), 1).otherwise(0)) \\\n",
    "    .withColumn(\"course_is_elective_for_DS\", when(col(\"elective_in_programs\").contains(\"DS\"), 1).otherwise(0)) \\\n",
    "    .withColumn(\"course_is_required_for_IS\", when(col(\"required_in_programs\").contains(\"IS\"), 1).otherwise(0)) \\\n",
    "    .withColumn(\"course_is_required_for_DS\", when(col(\"required_in_programs\").contains(\"DS\"), 1).otherwise(0)) \\\n",
    "    .drop(\"elective_in_programs\", \"required_in_programs\", \"prerequisites\", \"key_assignments\")\n",
    "\n",
    "# Show the flattened DataFrame\n",
    "df_sections_prep_flattened.show(5)\n",
    "\n",
    "# Display the schema of the flattened DataFrame\n",
    "df_sections_prep_flattened.printSchema()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dd3d88-efe9-4d0c-90ce-941ef6de84e2",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "Load the data frame you created in question 7 into `elasticsearch`, under the index `sections`.  Demonstrate the data is in the index by querying back it with PySpark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39d2c484-7857-4064-a60c-c1ec0004b370",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>academic_year</th>\n",
       "      <th>capacity</th>\n",
       "      <th>course</th>\n",
       "      <th>course_credits</th>\n",
       "      <th>course_description</th>\n",
       "      <th>course_is_elective_for_DS</th>\n",
       "      <th>course_is_elective_for_IS</th>\n",
       "      <th>course_is_required_for_DS</th>\n",
       "      <th>course_is_required_for_IS</th>\n",
       "      <th>course_name</th>\n",
       "      <th>enrollment</th>\n",
       "      <th>section</th>\n",
       "      <th>term</th>\n",
       "      <th>term_name</th>\n",
       "      <th>term_semester</th>\n",
       "      <th>term_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-2022</td>\n",
       "      <td>24</td>\n",
       "      <td>IST615</td>\n",
       "      <td>3</td>\n",
       "      <td>Cloud services creation and management. Practi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cloud Management</td>\n",
       "      <td>19</td>\n",
       "      <td>M001</td>\n",
       "      <td>1222</td>\n",
       "      <td>Spring 2022</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-2022</td>\n",
       "      <td>28</td>\n",
       "      <td>IST621</td>\n",
       "      <td>3</td>\n",
       "      <td>Information and technology management overview...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Information Management and Technology</td>\n",
       "      <td>28</td>\n",
       "      <td>M001</td>\n",
       "      <td>1222</td>\n",
       "      <td>Spring 2022</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-2022</td>\n",
       "      <td>24</td>\n",
       "      <td>IST621</td>\n",
       "      <td>3</td>\n",
       "      <td>Information and technology management overview...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Information Management and Technology</td>\n",
       "      <td>22</td>\n",
       "      <td>M002</td>\n",
       "      <td>1222</td>\n",
       "      <td>Spring 2022</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-2022</td>\n",
       "      <td>24</td>\n",
       "      <td>IST659</td>\n",
       "      <td>3</td>\n",
       "      <td>Definition, development, and management of dat...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Administration Concepts and Database Mana...</td>\n",
       "      <td>24</td>\n",
       "      <td>M001</td>\n",
       "      <td>1222</td>\n",
       "      <td>Spring 2022</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-2022</td>\n",
       "      <td>20</td>\n",
       "      <td>IST687</td>\n",
       "      <td>3</td>\n",
       "      <td>Introduces information professionals to fundam...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Introduction to Data Science</td>\n",
       "      <td>18</td>\n",
       "      <td>M001</td>\n",
       "      <td>1222</td>\n",
       "      <td>Spring 2022</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  academic_year  capacity  course  course_credits  \\\n",
       "0     2021-2022        24  IST615               3   \n",
       "1     2021-2022        28  IST621               3   \n",
       "2     2021-2022        24  IST621               3   \n",
       "3     2021-2022        24  IST659               3   \n",
       "4     2021-2022        20  IST687               3   \n",
       "\n",
       "                                  course_description  \\\n",
       "0  Cloud services creation and management. Practi...   \n",
       "1  Information and technology management overview...   \n",
       "2  Information and technology management overview...   \n",
       "3  Definition, development, and management of dat...   \n",
       "4  Introduces information professionals to fundam...   \n",
       "\n",
       "   course_is_elective_for_DS  course_is_elective_for_IS  \\\n",
       "0                          0                          0   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "3                          0                          0   \n",
       "4                          0                          1   \n",
       "\n",
       "   course_is_required_for_DS  course_is_required_for_IS  \\\n",
       "0                          1                          1   \n",
       "1                          0                          1   \n",
       "2                          0                          1   \n",
       "3                          1                          1   \n",
       "4                          1                          0   \n",
       "\n",
       "                                         course_name  enrollment section  \\\n",
       "0                                   Cloud Management          19    M001   \n",
       "1              Information Management and Technology          28    M001   \n",
       "2              Information Management and Technology          22    M002   \n",
       "3  Data Administration Concepts and Database Mana...          24    M001   \n",
       "4                       Introduction to Data Science          18    M001   \n",
       "\n",
       "   term    term_name term_semester  term_year  \n",
       "0  1222  Spring 2022        Spring       2022  \n",
       "1  1222  Spring 2022        Spring       2022  \n",
       "2  1222  Spring 2022        Spring       2022  \n",
       "3  1222  Spring 2022        Spring       2022  \n",
       "4  1222  Spring 2022        Spring       2022  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#8 load wide_sections_flattened into elasticsearch\n",
    "\n",
    "df_sections_prep_flattened.write.mode(\"Overwrite\").format(\"es\").save(\"sections/_doc\")\n",
    "\n",
    "# read back from Elasticsearch\n",
    "df_sections_elastic = spark.read.format(\"es\").load(\"sections/_doc\")\n",
    "df_sections_elastic.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa738b4b-6970-46d4-b5dc-3c766f7fe64b",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "Similar to question 4, prepare the `enrollments` for loading into `cassandra` and `elasticsearch` with Spark or Spark SQL. For this wide table we want to include the same reference data for `sections` but include the `student` attributes and the `program` data associated with the student. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce4ea5ef-282b-4aca-86c3-5401ef105088",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 100:=================================================>     (67 + 1) / 75]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------+------+-------+----------+-----+------------+--------+-----------+-------------+---------+-------------+--------------+--------------------+--------------------+-------------------------+-------------------------+-------------------------+-------------------------+------------+-------+---------------+------------------------+------------+------------------------+------------+\n",
      "|term|course_enrollment|course|section|student_id|grade|grade_points|capacity|  term_name|term_semester|term_year|academic_year|course_credits|         course_name|  course_description|course_is_elective_for_IS|course_is_elective_for_DS|course_is_required_for_IS|course_is_required_for_DS|student_name|program|program_credits|program_elective_courses|program_name|program_required_courses|program_type|\n",
      "+----+-----------------+------+-------+----------+-----+------------+--------+-----------+-------------+---------+-------------+--------------+--------------------+--------------------+-------------------------+-------------------------+-------------------------+-------------------------+------------+-------+---------------+------------------------+------------+------------------------+------------+\n",
      "|1232|               21|IST621|   M001|artiechoke|    A|         4.0|      28|Spring 2023|       Spring|     2023|    2022-2023|             3|Information Manag...|Information and t...|                        0|                        0|                        1|                        0| Artie Choke|     DS|             34|        [IST769, IST714]|Data Science|    [IST659, IST615, ...|     Masters|\n",
      "|1231|               18|IST659|   M002|artiechoke|    A|         4.0|      20|  Fall 2022|         Fall|     2022|    2022-2023|             3|Data Administrati...|Definition, devel...|                        0|                        0|                        1|                        1| Artie Choke|     DS|             34|        [IST769, IST714]|Data Science|    [IST659, IST615, ...|     Masters|\n",
      "|1231|               12|IST615|   M001|artiechoke|    A|         4.0|      24|  Fall 2022|         Fall|     2022|    2022-2023|             3|    Cloud Management|Cloud services cr...|                        0|                        0|                        1|                        1| Artie Choke|     DS|             34|        [IST769, IST714]|Data Science|    [IST659, IST615, ...|     Masters|\n",
      "|1231|                6|IST687|   M002|artiechoke|    A|         4.0|      24|  Fall 2022|         Fall|     2022|    2022-2023|             3|Introduction to D...|Introduces inform...|                        1|                        0|                        0|                        1| Artie Choke|     DS|             34|        [IST769, IST714]|Data Science|    [IST659, IST615, ...|     Masters|\n",
      "|1222|               18|IST615|   M001|peteterpan|    A|         4.0|      24|Spring 2022|       Spring|     2022|    2021-2022|             3|    Cloud Management|Cloud services cr...|                        0|                        0|                        1|                        1| Pete Terpan|     DS|             34|        [IST769, IST714]|Data Science|    [IST659, IST615, ...|     Masters|\n",
      "+----+-----------------+------+-------+----------+-----+------------+--------+-----------+-------------+---------+-------------+--------------+--------------------+--------------------+-------------------------+-------------------------+-------------------------+-------------------------+------------+-------+---------------+------------------------+------------+------------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- term: integer (nullable = true)\n",
      " |-- course_enrollment: integer (nullable = true)\n",
      " |-- course: string (nullable = true)\n",
      " |-- section: string (nullable = true)\n",
      " |-- student_id: string (nullable = true)\n",
      " |-- grade: string (nullable = true)\n",
      " |-- grade_points: double (nullable = true)\n",
      " |-- capacity: integer (nullable = true)\n",
      " |-- term_name: string (nullable = true)\n",
      " |-- term_semester: string (nullable = true)\n",
      " |-- term_year: integer (nullable = true)\n",
      " |-- academic_year: string (nullable = true)\n",
      " |-- course_credits: integer (nullable = true)\n",
      " |-- course_name: string (nullable = true)\n",
      " |-- course_description: string (nullable = true)\n",
      " |-- course_is_elective_for_IS: integer (nullable = true)\n",
      " |-- course_is_elective_for_DS: integer (nullable = true)\n",
      " |-- course_is_required_for_IS: integer (nullable = true)\n",
      " |-- course_is_required_for_DS: integer (nullable = true)\n",
      " |-- student_name: string (nullable = true)\n",
      " |-- program: string (nullable = true)\n",
      " |-- program_credits: integer (nullable = true)\n",
      " |-- program_elective_courses: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- program_name: string (nullable = true)\n",
      " |-- program_required_courses: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- program_type: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#9 create wide_enrollments\n",
    "\n",
    "from pyspark.sql.functions import col, array_contains, when\n",
    "\n",
    "# Joining enrollment data with sections, students, and programs using df_sections_prep_flatten\n",
    "df_enrollments_prep = df_enrollments.alias(\"enrollments\") \\\n",
    "    .join(df_sections_prep_flattened.alias(\"sections\"), \n",
    "          (col(\"enrollments.term\") == col(\"sections.term\")) &\n",
    "          (col(\"enrollments.course\") == col(\"sections.course\")) &\n",
    "          (col(\"enrollments.section\") == col(\"sections.section\")), \n",
    "          how=\"left\") \\\n",
    "    .join(df_students.alias(\"students\"), col(\"enrollments.student_id\") == col(\"students._id\"), how=\"left\") \\\n",
    "    .join(df_programs.alias(\"programs\"), col(\"students.program\") == col(\"programs.code\"), how=\"left\") \\\n",
    "    .select(\n",
    "        col(\"enrollments.term\").alias(\"term\"),\n",
    "        col(\"enrollments.course_enrollment\").alias(\"course_enrollment\"),\n",
    "        col(\"enrollments.course\"),\n",
    "        col(\"enrollments.section\"),\n",
    "        col(\"enrollments.student_id\"),\n",
    "        col(\"enrollments.grade\"),\n",
    "        col(\"enrollments.grade_points\"),\n",
    "        \n",
    "        col(\"sections.capacity\"),\n",
    "        col(\"sections.term_name\"),\n",
    "        col(\"sections.term_semester\"),\n",
    "        col(\"sections.term_year\"),\n",
    "        col(\"sections.academic_year\"),\n",
    "        col(\"sections.course_credits\"),\n",
    "        col(\"sections.course_name\"),\n",
    "        col(\"sections.course_description\"),\n",
    "        col(\"sections.course_is_elective_for_IS\"),\n",
    "        col(\"sections.course_is_elective_for_DS\"),\n",
    "        col(\"sections.course_is_required_for_IS\"),\n",
    "        col(\"sections.course_is_required_for_DS\"),\n",
    "    \n",
    "        col(\"students.name\").alias(\"student_name\"),\n",
    "        col(\"students.program\"),\n",
    "        \n",
    "        col(\"programs.credits\").alias(\"program_credits\"),\n",
    "        col(\"programs.elective_courses\").alias(\"program_elective_courses\"),\n",
    "        col(\"programs.name\").alias(\"program_name\"),\n",
    "        col(\"programs.required_courses\").alias(\"program_required_courses\"),\n",
    "        col(\"programs.type\").alias(\"program_type\")\n",
    "    )\n",
    "\n",
    "# Show and print schema\n",
    "df_enrollments_prep.show(5)\n",
    "df_enrollments_prep.printSchema()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae284c8-096a-4987-98cf-0800cedced12",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "Load the data frame you created in question 8 into `elasticsearch`, under the index `enrollments`. This time, just Omit all array types to make the problem simpler (`elective_courses`, `key_assignments`, `course_prerequisites`, etc...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f024b1e-62a3-4596-bc46-af624e72238a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enrollments_prep_no_arrays = df_enrollments_prep.drop(\"program_elective_courses\")\\\n",
    "                                        .drop(\"program_required_courses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a42dedc-62c4-4b83-b431-2a3474834901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>academic_year</th>\n",
       "      <th>capacity</th>\n",
       "      <th>course</th>\n",
       "      <th>course_credits</th>\n",
       "      <th>course_description</th>\n",
       "      <th>course_enrollment</th>\n",
       "      <th>course_is_elective_for_DS</th>\n",
       "      <th>course_is_elective_for_IS</th>\n",
       "      <th>course_is_required_for_DS</th>\n",
       "      <th>course_is_required_for_IS</th>\n",
       "      <th>...</th>\n",
       "      <th>program_credits</th>\n",
       "      <th>program_name</th>\n",
       "      <th>program_type</th>\n",
       "      <th>section</th>\n",
       "      <th>student_id</th>\n",
       "      <th>student_name</th>\n",
       "      <th>term</th>\n",
       "      <th>term_name</th>\n",
       "      <th>term_semester</th>\n",
       "      <th>term_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-2023</td>\n",
       "      <td>28</td>\n",
       "      <td>IST621</td>\n",
       "      <td>3</td>\n",
       "      <td>Information and technology management overview...</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Masters</td>\n",
       "      <td>M001</td>\n",
       "      <td>artiechoke</td>\n",
       "      <td>Artie Choke</td>\n",
       "      <td>1232</td>\n",
       "      <td>Spring 2023</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-2023</td>\n",
       "      <td>20</td>\n",
       "      <td>IST659</td>\n",
       "      <td>3</td>\n",
       "      <td>Definition, development, and management of dat...</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Masters</td>\n",
       "      <td>M002</td>\n",
       "      <td>artiechoke</td>\n",
       "      <td>Artie Choke</td>\n",
       "      <td>1231</td>\n",
       "      <td>Fall 2022</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-2023</td>\n",
       "      <td>24</td>\n",
       "      <td>IST615</td>\n",
       "      <td>3</td>\n",
       "      <td>Cloud services creation and management. Practi...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Masters</td>\n",
       "      <td>M001</td>\n",
       "      <td>artiechoke</td>\n",
       "      <td>Artie Choke</td>\n",
       "      <td>1231</td>\n",
       "      <td>Fall 2022</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-2023</td>\n",
       "      <td>24</td>\n",
       "      <td>IST687</td>\n",
       "      <td>3</td>\n",
       "      <td>Introduces information professionals to fundam...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Masters</td>\n",
       "      <td>M002</td>\n",
       "      <td>artiechoke</td>\n",
       "      <td>Artie Choke</td>\n",
       "      <td>1231</td>\n",
       "      <td>Fall 2022</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-2022</td>\n",
       "      <td>24</td>\n",
       "      <td>IST615</td>\n",
       "      <td>3</td>\n",
       "      <td>Cloud services creation and management. Practi...</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Masters</td>\n",
       "      <td>M001</td>\n",
       "      <td>peteterpan</td>\n",
       "      <td>Pete Terpan</td>\n",
       "      <td>1222</td>\n",
       "      <td>Spring 2022</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  academic_year  capacity  course  course_credits  \\\n",
       "0     2022-2023        28  IST621               3   \n",
       "1     2022-2023        20  IST659               3   \n",
       "2     2022-2023        24  IST615               3   \n",
       "3     2022-2023        24  IST687               3   \n",
       "4     2021-2022        24  IST615               3   \n",
       "\n",
       "                                  course_description  course_enrollment  \\\n",
       "0  Information and technology management overview...                 21   \n",
       "1  Definition, development, and management of dat...                 18   \n",
       "2  Cloud services creation and management. Practi...                 12   \n",
       "3  Introduces information professionals to fundam...                  6   \n",
       "4  Cloud services creation and management. Practi...                 18   \n",
       "\n",
       "   course_is_elective_for_DS  course_is_elective_for_IS  \\\n",
       "0                          0                          0   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "3                          0                          1   \n",
       "4                          0                          0   \n",
       "\n",
       "   course_is_required_for_DS  course_is_required_for_IS  ... program_credits  \\\n",
       "0                          0                          1  ...              34   \n",
       "1                          1                          1  ...              34   \n",
       "2                          1                          1  ...              34   \n",
       "3                          1                          0  ...              34   \n",
       "4                          1                          1  ...              34   \n",
       "\n",
       "   program_name  program_type section  student_id student_name  term  \\\n",
       "0  Data Science       Masters    M001  artiechoke  Artie Choke  1232   \n",
       "1  Data Science       Masters    M002  artiechoke  Artie Choke  1231   \n",
       "2  Data Science       Masters    M001  artiechoke  Artie Choke  1231   \n",
       "3  Data Science       Masters    M002  artiechoke  Artie Choke  1231   \n",
       "4  Data Science       Masters    M001  peteterpan  Pete Terpan  1222   \n",
       "\n",
       "     term_name term_semester term_year  \n",
       "0  Spring 2023        Spring      2023  \n",
       "1    Fall 2022          Fall      2022  \n",
       "2    Fall 2022          Fall      2022  \n",
       "3    Fall 2022          Fall      2022  \n",
       "4  Spring 2022        Spring      2022  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10 wide_enrollments to elastic search\n",
    "\n",
    "# Write to Elasticsearch\n",
    "df_enrollments_prep_no_arrays.write.mode(\"Overwrite\").format(\"es\").save(\"enrollments/_doc\")\n",
    "\n",
    "# Read back from Elasticsearch\n",
    "df_enrollments_elastic = spark.read.format(\"es\").load(\"enrollments/_doc\")\n",
    "df_enrollments_elastic.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a1726ef-a559-4355-b70b-40a5d4837907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load wide_enrollments into cassandra\n",
    "\n",
    "#df_enrollments_prep.write \\\n",
    "#    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "#    .mode(\"Append\") \\\n",
    "#    .option(\"table\", \"wide_enrollments\") \\\n",
    "#    .option(\"keyspace\", \"ischooldb\") \\\n",
    "#    .option(\"spark.cassandra.connection.host\", cassandra_host) \\\n",
    "#    .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40baf832-3a14-45c9-9594-d607439b845a",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "\n",
    "Write spark to clear the `neo4j` database of all nodes and relationships.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd7a903e-789b-4b01-8501-6041190b50c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#11 reset neo4j database \n",
    "\n",
    "# Define the Cypher query to delete all nodes and relationships\n",
    "cypher_query = \"MATCH (n) DETACH DELETE n\"\n",
    "\n",
    "# Execute the Cypher query using the SparkSession\n",
    "spark.read.format(\"org.neo4j.spark.DataSource\") \\\n",
    "    .option(\"url\", bolt_url) \\\n",
    "    .option(\"query\", cypher_query) \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6910199-edde-418d-b6fa-06c5d810ce3d",
   "metadata": {},
   "source": [
    "### Question 12\n",
    "\n",
    "Load the `courses` and `program` data into `neo4j` as nodes. Exclude the `requirements`, `electives` and `prerequisites` from the node attributes. Demonstrate the data in `neo4j` by querying back it using one or more Cypher queries. NOTE: the Neo4J `name` attribute is what will display on the node bubbles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7c4094d-f632-456b-81c8-41b851e2dfb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+-------+--------------------+--------------------+----------------+--------------------+-------------+--------------------+\n",
      "|   _id|  code|credits|         description|elective_in_programs| key_assignments|                name|prerequisites|required_in_programs|\n",
      "+------+------+-------+--------------------+--------------------+----------------+--------------------+-------------+--------------------+\n",
      "|IST659|IST659|      3|Definition, devel...|                  []|       [project]|Data Administrati...|           []|            [IS, DS]|\n",
      "|IST722|IST722|      3|Introduction to c...|                [IS]| [project, exam]|    Data Warehousing|     [IST659]|                  []|\n",
      "|IST769|IST769|      3|Analyze relationa...|                [DS]| [project, exam]|Advanced Big Data...|     [IST659]|                  []|\n",
      "|IST615|IST615|      3|Cloud services cr...|                  []|[project, paper]|    Cloud Management|           []|            [IS, DS]|\n",
      "|IST714|IST714|      3|Advanced, lab-bas...|            [IS, DS]|       [project]|  Cloud Architecture|     [IST615]|                  []|\n",
      "+------+------+-------+--------------------+--------------------+----------------+--------------------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- _id: string (nullable = true)\n",
      " |-- code: string (nullable = true)\n",
      " |-- credits: integer (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- elective_in_programs: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- key_assignments: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- prerequisites: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- required_in_programs: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "+---+----+-------+--------------------+--------------------+--------------------+-----------+\n",
      "|_id|code|credits|    elective_courses|                name|    required_courses|       type|\n",
      "+---+----+-------+--------------------+--------------------+--------------------+-----------+\n",
      "| IS|  IS|     36|[IST722, IST714, ...| Information Systems|[IST659, IST615, ...|    Masters|\n",
      "| DS|  DS|     34|    [IST769, IST714]|        Data Science|[IST659, IST615, ...|    Masters|\n",
      "|BDC| BDC|      9|                null|Data Engineering ...|[IST659, IST722, ...|Certificate|\n",
      "|CCC| CCC|      9|                null|Cloud Computing C...|[IST621, IST615, ...|Certificate|\n",
      "|MLC| MLC|      9|                null|Machine Learning ...|[IST687, IST707, ...|Certificate|\n",
      "+---+----+-------+--------------------+--------------------+--------------------+-----------+\n",
      "\n",
      "root\n",
      " |-- _id: string (nullable = true)\n",
      " |-- code: string (nullable = true)\n",
      " |-- credits: integer (nullable = true)\n",
      " |-- elective_courses: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- required_courses: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_courses.show(5)\n",
    "df_courses.printSchema()\n",
    "\n",
    "df_programs.show(5)\n",
    "df_programs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "021b1cd7-c412-4f03-a4b8-8792f2cd0eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register DataFrames as temporary views\n",
    "df_courses.createOrReplaceTempView(\"courses\")\n",
    "df_programs.createOrReplaceTempView(\"programs\")\n",
    "\n",
    "# Execute SQL queries to select necessary columns and create new DataFrames\n",
    "courses_sql = \"\"\"\n",
    "SELECT code, credits, description, name\n",
    "FROM courses\n",
    "\"\"\"\n",
    "\n",
    "programs_sql = \"\"\"\n",
    "SELECT code, credits, name, type\n",
    "FROM programs\n",
    "\"\"\"\n",
    "\n",
    "# Create new DataFrames with desired attributes\n",
    "df_courses_with_req_attributes = spark.sql(courses_sql)\n",
    "df_programs_with_req_attributes = spark.sql(programs_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71eeb25c-fa18-4702-9595-34f443aca315",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#12a load courses into Neo4j\n",
    "\n",
    "df_courses_with_req_attributes.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "  .mode(\"Overwrite\")\\\n",
    "  .option(\"url\", bolt_url) \\\n",
    "  .option(\"labels\", \"courses\") \\\n",
    "  .option(\"node.keys\",\"name\") \\\n",
    "  .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf6d0bad-1885-465e-9f6d-59918962e682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+--------------------+--------------------+-------+------+\n",
      "|<id>| <labels>|                name|         description|credits|  code|\n",
      "+----+---------+--------------------+--------------------+-------+------+\n",
      "|   0|[courses]|Data Administrati...|Definition, devel...|      3|IST659|\n",
      "|   1|[courses]|    Data Warehousing|Introduction to c...|      3|IST722|\n",
      "|   2|[courses]|Advanced Big Data...|Analyze relationa...|      3|IST769|\n",
      "|   3|[courses]|    Cloud Management|Cloud services cr...|      3|IST615|\n",
      "|   4|[courses]|  Cloud Architecture|Advanced, lab-bas...|      3|IST714|\n",
      "+----+---------+--------------------+--------------------+-------+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- <id>: long (nullable = false)\n",
      " |-- <labels>: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- credits: long (nullable = true)\n",
      " |-- code: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read back from Neo4j\n",
    "df1 = spark.read.format(\"org.neo4j.spark.DataSource\") \\\n",
    "  .option(\"url\", bolt_url) \\\n",
    "  .option(\"labels\", \"courses\") \\\n",
    "  .load()\n",
    "df1.show(5)\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69aa723b-5479-4232-aca3-0197e199cc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#12b load programs into neo4j\n",
    "\n",
    "df_programs_with_req_attributes.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "  .mode(\"Overwrite\")\\\n",
    "  .option(\"url\", bolt_url) \\\n",
    "  .option(\"labels\", \"programs\") \\\n",
    "  .option(\"node.keys\",\"name\") \\\n",
    "  .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0c0d3c7-ec9a-428c-93a2-d6a90740165e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+-----------+--------------------+-------+----+\n",
      "|<id>|  <labels>|       type|                name|credits|code|\n",
      "+----+----------+-----------+--------------------+-------+----+\n",
      "|   9|[programs]|    Masters| Information Systems|     36|  IS|\n",
      "|  10|[programs]|    Masters|        Data Science|     34|  DS|\n",
      "|  11|[programs]|Certificate|Data Engineering ...|      9| BDC|\n",
      "|  12|[programs]|Certificate|Cloud Computing C...|      9| CCC|\n",
      "|  13|[programs]|Certificate|Machine Learning ...|      9| MLC|\n",
      "+----+----------+-----------+--------------------+-------+----+\n",
      "\n",
      "root\n",
      " |-- <id>: long (nullable = false)\n",
      " |-- <labels>: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- credits: long (nullable = true)\n",
      " |-- code: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read back from Neo4j\n",
    "df2 = spark.read.format(\"org.neo4j.spark.DataSource\") \\\n",
    "  .option(\"url\", bolt_url) \\\n",
    "  .option(\"labels\", \"programs\") \\\n",
    "  .load()\n",
    "df2.show(5)\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b936d928-921f-493d-9087-6961983df5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MATCH (p:programs) RETURN p;\n",
    "# MATCH (c:courses) RETURN c;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5508275-5202-43f5-8adf-773dc22fc681",
   "metadata": {},
   "source": [
    "### Question 13\n",
    "\n",
    "Load the `requirements` and `electives` data into `neo4j` as relationships to the nodes you created in Question 12. Use the `program` data to form the `required` and `elective` course relationships. Demonstrate the relationships in `neo4j` are present by querying back it using one or more Cypher queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f782d89-fa86-4c79-b1f0-baf383c47100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#13a program course requirements\n",
    "\n",
    "from pyspark.sql.functions import explode\n",
    "\n",
    "# Explode the array containing required courses\n",
    "required = df_programs.select(\"code\", explode(\"required_courses\").alias(\"required_course\"))\n",
    "\n",
    "# Load required courses into Neo4j\n",
    "cql_required = '''\n",
    "MATCH (c:courses), (p:programs)\n",
    "WHERE c.code = event.required_course AND p.code = event.code\n",
    "MERGE (p)-[:REQUIRES]->(c)\n",
    "'''\n",
    "\n",
    "required.write.format(\"org.neo4j.spark.DataSource\") \\\n",
    "    .mode(\"Overwrite\") \\\n",
    "    .option(\"url\", bolt_url) \\\n",
    "    .option(\"query\", cql_required) \\\n",
    "    .save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a69d06b-89eb-4d4a-80ed-dbb50422f64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+------------+-------------------+\n",
      "|course_code|         course_name|program_code|       program_name|\n",
      "+-----------+--------------------+------------+-------------------+\n",
      "|     IST621|Information Manag...|          IS|Information Systems|\n",
      "|     IST615|    Cloud Management|          IS|Information Systems|\n",
      "|     IST659|Data Administrati...|          IS|Information Systems|\n",
      "|     IST707|Applied Machine L...|          DS|       Data Science|\n",
      "|     IST718|  Big Data Analytics|          DS|       Data Science|\n",
      "+-----------+--------------------+------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- course_code: string (nullable = true)\n",
      " |-- course_name: string (nullable = true)\n",
      " |-- program_code: string (nullable = true)\n",
      " |-- program_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query program course requirements from Neo4j\n",
    "cql_requirements = '''\n",
    "MATCH (p:programs)-[:REQUIRES]->(c:courses)\n",
    "RETURN c.code AS course_code, c.name AS course_name, p.code AS program_code, p.name AS program_name\n",
    "'''\n",
    "\n",
    "df_requirements = spark.read.format(\"org.neo4j.spark.DataSource\") \\\n",
    "    .option(\"url\", bolt_url) \\\n",
    "    .option(\"query\", cql_requirements) \\\n",
    "    .load()\n",
    "\n",
    "df_requirements.show(5)\n",
    "df_requirements.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9abc97bf-a75a-48d9-902a-aae259211e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#13b program course electives\n",
    "\n",
    "# Explode the array containing elective courses\n",
    "elective = df_programs.select(\"code\", explode(\"elective_courses\").alias(\"elective_course\"))\n",
    "\n",
    "# Load elective courses into Neo4j\n",
    "cql_elective = '''\n",
    "MATCH (c:courses), (p:programs)\n",
    "WHERE c.code = event.elective_course AND p.code = event.code\n",
    "MERGE (p)-[:ELECTIVE]->(c)\n",
    "'''\n",
    "\n",
    "elective.write.format(\"org.neo4j.spark.DataSource\") \\\n",
    "    .mode(\"Overwrite\") \\\n",
    "    .option(\"url\", bolt_url) \\\n",
    "    .option(\"query\", cql_elective) \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d5bcd08-6742-499f-a9c3-f167ec204600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+------------+-------------------+\n",
      "|course_code|         course_name|program_code|       program_name|\n",
      "+-----------+--------------------+------------+-------------------+\n",
      "|     IST722|    Data Warehousing|          IS|Information Systems|\n",
      "|     IST714|  Cloud Architecture|          IS|Information Systems|\n",
      "|     IST687|Introduction to D...|          IS|Information Systems|\n",
      "|     IST707|Applied Machine L...|          IS|Information Systems|\n",
      "|     IST769|Advanced Big Data...|          DS|       Data Science|\n",
      "+-----------+--------------------+------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- course_code: string (nullable = true)\n",
      " |-- course_name: string (nullable = true)\n",
      " |-- program_code: string (nullable = true)\n",
      " |-- program_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query program course electives from Neo4j\n",
    "cql_electives = '''\n",
    "MATCH (p:programs)-[:ELECTIVE]->(c:courses)\n",
    "RETURN c.code AS course_code, c.name AS course_name, p.code AS program_code, p.name AS program_name\n",
    "'''\n",
    "\n",
    "df_electives = spark.read.format(\"org.neo4j.spark.DataSource\") \\\n",
    "    .option(\"url\", bolt_url) \\\n",
    "    .option(\"query\", cql_electives) \\\n",
    "    .load()\n",
    "\n",
    "df_electives.show(5)\n",
    "df_electives.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ad62a7-505a-4bb8-a2bd-3756cf6719d5",
   "metadata": {},
   "source": [
    "### Question 14\n",
    "\n",
    "Load the `prerequisites` into `neo4j` as relationships to the `course` nodes you created in Question 12. Demonstrate the relationships in `neo4j` are present by querying back it using one or more Cypher queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b9e586b-c5be-4908-bc31-26ab6ef5ba9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#14 course prerequisites \n",
    "\n",
    "from pyspark.sql.functions import explode\n",
    "\n",
    "# Explode the array containing prerequisites\n",
    "prerequisites = df_courses.select(\"code\", explode(\"prerequisites\").alias(\"prerequisite_code\"))\n",
    "\n",
    "# Load prerequisites into Neo4j\n",
    "cql_prerequisites = '''\n",
    "MATCH (c1:courses), (c2:courses)\n",
    "WHERE c1.code = event.code AND c2.code = event.prerequisite_code\n",
    "MERGE (c1)-[:PREREQUISITE]->(c2)\n",
    "'''\n",
    "\n",
    "prerequisites.write.format(\"org.neo4j.spark.DataSource\") \\\n",
    "    .mode(\"Overwrite\") \\\n",
    "    .option(\"url\", bolt_url) \\\n",
    "    .option(\"query\", cql_prerequisites) \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9c61a034-140a-4dca-9921-70ad1997e99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-----------------+--------------------+\n",
      "|course_code|         course_name|prerequisite_code|   prerequisite_name|\n",
      "+-----------+--------------------+-----------------+--------------------+\n",
      "|     IST722|    Data Warehousing|           IST659|Data Administrati...|\n",
      "|     IST769|Advanced Big Data...|           IST659|Data Administrati...|\n",
      "|     IST714|  Cloud Architecture|           IST615|    Cloud Management|\n",
      "|     IST707|Applied Machine L...|           IST687|Introduction to D...|\n",
      "|     IST718|  Big Data Analytics|           IST687|Introduction to D...|\n",
      "+-----------+--------------------+-----------------+--------------------+\n",
      "\n",
      "root\n",
      " |-- course_code: string (nullable = true)\n",
      " |-- course_name: string (nullable = true)\n",
      " |-- prerequisite_code: string (nullable = true)\n",
      " |-- prerequisite_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query course prerequisites from Neo4j\n",
    "cql_course_prerequisites = '''\n",
    "MATCH (c1:courses)-[:PREREQUISITE]->(c2:courses)\n",
    "RETURN c1.code AS course_code, c1.name AS course_name, c2.code AS prerequisite_code, c2.name AS prerequisite_name\n",
    "'''\n",
    "\n",
    "df_course_prerequisites = spark.read.format(\"org.neo4j.spark.DataSource\") \\\n",
    "    .option(\"url\", bolt_url) \\\n",
    "    .option(\"query\", cql_course_prerequisites) \\\n",
    "    .load()\n",
    "\n",
    "df_course_prerequisites.show(5)\n",
    "df_course_prerequisites.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c4d61d-5076-4d6e-9f54-03e437d18333",
   "metadata": {},
   "source": [
    "### Question 15\n",
    "\n",
    "Write a Cypher query to display courses which are required by both the `IS` and `DS` programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2252e315-eaba-47ee-9f8e-11fc43529c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------+--------------------+\n",
      "|course_code|         course_name|course_credits|  course_description|\n",
      "+-----------+--------------------+--------------+--------------------+\n",
      "|     IST615|    Cloud Management|             3|Cloud services cr...|\n",
      "|     IST659|Data Administrati...|             3|Definition, devel...|\n",
      "+-----------+--------------------+--------------+--------------------+\n",
      "\n",
      "root\n",
      " |-- course_code: string (nullable = true)\n",
      " |-- course_name: string (nullable = true)\n",
      " |-- course_credits: long (nullable = true)\n",
      " |-- course_description: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#15 Cypher query courses required in DS and IS\n",
    "\n",
    "# Define the Cypher query\n",
    "cql_courses_required_by_both_programs = '''\n",
    "MATCH (is:programs {code: 'IS'})-[:REQUIRES]->(course:courses)\n",
    "WITH COLLECT(DISTINCT course.code) AS is_required_courses\n",
    "MATCH (ds:programs {code: 'DS'})-[:REQUIRES]->(course:courses)\n",
    "WHERE course.code IN is_required_courses\n",
    "RETURN course.code AS course_code, course.name AS course_name, course.credits as course_credits, course.description as course_description\n",
    "'''\n",
    "\n",
    "# Execute the Cypher query using Neo4j DataSource\n",
    "df_courses_required_by_both_programs = spark.read.format(\"org.neo4j.spark.DataSource\") \\\n",
    "    .option(\"url\", bolt_url) \\\n",
    "    .option(\"query\", cql_courses_required_by_both_programs) \\\n",
    "    .load()\n",
    "\n",
    "# Show the result\n",
    "df_courses_required_by_both_programs.show()\n",
    "df_courses_required_by_both_programs.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbe6590-97e2-477f-b860-7ffd5fe63640",
   "metadata": {},
   "source": [
    "### Question 16\n",
    "\n",
    "Write a Cypher query to retrieve the `course code`, `course title`, and the count of programs the course is a requirement in. Write as a Cypher query but retrieve the  output as a Spark Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7b68985d-c57c-42b3-87a5-4b9c4b6114f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-------------+\n",
      "|course_code|        course_title|program_count|\n",
      "+-----------+--------------------+-------------+\n",
      "|     IST621|Information Manag...|            2|\n",
      "|     IST615|    Cloud Management|            3|\n",
      "|     IST659|Data Administrati...|            3|\n",
      "|     IST707|Applied Machine L...|            2|\n",
      "|     IST718|  Big Data Analytics|            2|\n",
      "|     IST687|Introduction to D...|            2|\n",
      "|     IST769|Advanced Big Data...|            1|\n",
      "|     IST722|    Data Warehousing|            1|\n",
      "|     IST714|  Cloud Architecture|            1|\n",
      "+-----------+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#16 Cypher to spark table\n",
    "\n",
    "# Define the Cypher query\n",
    "cql_course_program_count = '''\n",
    "MATCH (p:programs)-[:REQUIRES]->(c:courses)\n",
    "WITH c.code AS course_code, c.name AS course_title, COUNT(DISTINCT p) AS program_count\n",
    "RETURN course_code, course_title, program_count\n",
    "'''\n",
    "\n",
    "# Execute the Cypher query using Neo4j DataSource\n",
    "df_course_program_count = spark.read.format(\"org.neo4j.spark.DataSource\") \\\n",
    "    .option(\"url\", bolt_url) \\\n",
    "    .option(\"query\", cql_course_program_count) \\\n",
    "    .load()\n",
    "\n",
    "# Show the result\n",
    "df_course_program_count.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172bc633",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Questions 17,18,19 and 20\n",
    "\n",
    "These are not spark questions as they use kibana."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
